{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trash Recognition Neural Network üß†"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "üìö This was an ML project for USC CSCI 467: Introduction to Machine Learning. My co-authors are Russell Tan and Pablo Tayun-Mazariegos. The premise is as follows:\n",
        "\n",
        "‚ôªÔ∏è Recycling is a well known solution to saving landfill space, however, many people do not know how or often make mistakes in sorting trash. Sorting recyclables before reaching the recycling facility is crucial for effective recycling as it keeps costs down by preventing clogged machinery and the need of manual sorting in the facilities. If contaminants were to pass, the final product would be deemed unsatisfactory and thrown into the landfill rather than being reused. This experiment's purpose is to help improve models designed to classify six different forms of waste: glass, cardboard, metal, paper, plastic and trash.\n",
        "\n",
        "üì¶ The classifier, which consists of some form of CNN, will take an image input containing a single piece of waste on a white background (or any solid color background). The model should then classify the object into one of six possible waste categories mentioned prior. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports\n",
        "\n",
        "We're mainly using `Pytorch` for the implementation of our Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbkkVyuZMj15"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N63RbH4MR5-y"
      },
      "source": [
        "## Step 1: Data Collection and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SHEZYKAS1ah"
      },
      "source": [
        "First, we load our dataset stored in a Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd6rJQ11dmDs",
        "outputId": "7296de1e-941d-46b1-9951-87e8a6bfae91"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "data_dir ='/content/drive/MyDrive/Colab Notebooks/Datasets/CCHANGCS_Garbage ClassificationDataset.zip (Unzipped Files)/Garbage classification/Garbage classification'\n",
        "classes = os.listdir(data_dir)\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqd5d7V8S45U"
      },
      "source": [
        "Preprocess the images to ideal sizes for the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtWTt4m9hiTV",
        "outputId": "ccba013a-64b2-40a4-9720-379c05c6ad7f"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Data augmentation and normalization for training\n",
        "# `target_size` changes according to the model\n",
        "target_size = (224,224)\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "    transforms.Resize(target_size),\n",
        "    transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "dataset = ImageFolder(data_dir, transform = transformations)\n",
        "print(dataset.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STKfN7QSTCrg"
      },
      "source": [
        "Assign each image with their assigned class for comparison purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BGHyqteIhmbJ",
        "outputId": "e8b163ad-6fce-4e06-925b-3c75616a8664"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_sample(img, label):\n",
        "    print(\"Label:\", dataset.classes[label], \"(Class No: \"+ str(label) + \")\")\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "\n",
        "dataset.classes[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EIH2HJ9Sw1U"
      },
      "source": [
        "Print sample of training data with assigned label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "r9NOgPvHhyAZ",
        "outputId": "414bdb30-417e-4f9e-ca01-7061f975cd66"
      },
      "outputs": [],
      "source": [
        "img, label = dataset[12]\n",
        "show_sample(img, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DGPgsy3TJyq"
      },
      "source": [
        "Randomly allocate images to Training, Dev, Test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6segIeush2fa",
        "outputId": "5681d75b-8eb2-4281-88ba-6df9df5e0b03"
      },
      "outputs": [],
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "print(dataset)\n",
        "print(len(dataset))\n",
        "total = len(dataset)\n",
        "\n",
        "print((total*0.7), (total*0.1), (total*0.2))\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [1769 , 253 , 505])\n",
        "\n",
        "len(train_ds), len(val_ds), len(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfk3Kb4XiIU6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers = 4, pin_memory = True)\n",
        "test_dl = DataLoader(test_ds, batch_size*2, num_workers = 4, pin_memory = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display test images and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgV35UftiMWs"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow = 16).permute(1, 2, 0))\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYO69yDOSHIQ"
      },
      "source": [
        "## Step 2: Training üèãÔ∏è‚Äç‚ôÄÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9h2Aln2TW5F"
      },
      "source": [
        "Base model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8u1kJr7idaK"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch {}: train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch+1, result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYGkdnzBSnoe"
      },
      "source": [
        "CNN models as classes. These models were all ran and benchmarked independently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr2nZDPxillr",
        "outputId": "d7dabee5-2154-48b3-b540-0be269dfb52f"
      },
      "outputs": [],
      "source": [
        "import torchvision.models\n",
        "from torchvision.models import list_models, get_model\n",
        "\n",
        "# List available models\n",
        "print(list_models())\n",
        "print(list_models(module=torchvision.models))\n",
        "\n",
        "# Initialize models, temporary use premade models\n",
        "class AlexNet(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = torchvision.models.alexnet(pretrained=True)\n",
        "        # for param in self.network.features.parameters():\n",
        "        #    param.requires_grad = False\n",
        "        self.network.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.5, inplace=False),\n",
        "        nn.Linear(in_features=9216, out_features=4096, bias=True),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(p=0.5, inplace=False),\n",
        "        nn.Linear(4096, 1024, True),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(1024, len(dataset.classes), True),\n",
        "        )\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "class MobileNet(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "        for param in self.network.parameters():\n",
        "            param.requires_grad = False\n",
        "        num_ftrs = self.network.classifier[1].in_features\n",
        "        self.network.classifier[1] = nn.Linear(num_ftrs, len(dataset.classes))\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "class AlexNet(ImageClassificationBase):\n",
        "    def __init__(self, num_classes = len(dataset.classes)):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(6400, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "class MobileNet(ImageClassificationBase):\n",
        "    def __init__(self, num_classes = len(dataset.classes)):\n",
        "        super(MobileNet, self).__init__()\n",
        "\n",
        "        def conv_bn(inp, oup, stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        def conv_dw(inp, oup, stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
        "                nn.BatchNorm2d(inp),\n",
        "                nn.ReLU(inplace=True),\n",
        "\n",
        "                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            conv_bn(  3,  32, 2),\n",
        "            conv_dw( 32,  64, 1),\n",
        "            conv_dw( 64, 128, 2),\n",
        "            conv_dw(128, 128, 1),\n",
        "            conv_dw(128, 256, 2),\n",
        "            conv_dw(256, 256, 1),\n",
        "            conv_dw(256, 512, 2),\n",
        "            conv_dw(512, 512, 1),\n",
        "            conv_dw(512, 512, 1),\n",
        "            conv_dw(512, 512, 1),\n",
        "            conv_dw(512, 512, 1),\n",
        "            conv_dw(512, 512, 1),\n",
        "            conv_dw(512, 1024, 2),\n",
        "            conv_dw(1024, 1024, 1),\n",
        "            nn.AvgPool2d(7),\n",
        "        )\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class ResNet50(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = models.resnet50(pretrained=True)\n",
        "\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "\n",
        "class ResNet101(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = models.resnet101(pretrained=True)\n",
        "        \n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "class ResNet18(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = models.resnet18(pretrained=True)\n",
        "        \n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "class WideResNet101(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = models.wide_resnet101_2(pretrained=True)\n",
        "        \n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "class MobileNet_V3L(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = torchvision.models.mobilenet_v3_large(pretrained=True)\n",
        "        self.network.classifier = nn.Sequential(\n",
        "            nn.Linear(960, 1280, bias=True),\n",
        "            nn.Hardswish(),\n",
        "            nn.Dropout(0.2, True),\n",
        "            nn.Linear(1280, len(dataset.classes), True)\n",
        "        )\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "class MobileNet_V3S(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
        "        self.network.classifier = nn.Sequential(\n",
        "            nn.Linear(576, 1024, bias=True),\n",
        "            nn.Hardswish(),\n",
        "            nn.Dropout(0.2, True),\n",
        "            nn.Linear(1024, len(dataset.classes), True)\n",
        "        )\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "class SqueezeNet_V1p1(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = torchvision.models.squeezenet1_1(pretrained=False)\n",
        "        self.network.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5, inplace=False),\n",
        "            nn.Conv2d(512, len(dataset.classes), kernel_size=(1, 1)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        )\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "class EfficientNetV2(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = models.efficientnet_v2_l(pretrained=True)\n",
        "        self.network.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.4, True),\n",
        "            nn.Linear(1280, len(dataset.classes), True)\n",
        "        )\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "model = AlexNet() # or any of the other models above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yt9sTXbTdXY"
      },
      "source": [
        "Choose a GPU for performance ‚ö°Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsuCBPW8jBH9",
        "outputId": "47fa96b5-4329-45bf-fa97-e4fc93e0b702"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "print(device)\n",
        "\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "test_dl = DeviceDataLoader(test_dl, device)\n",
        "to_device(model, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Qukft5TlOZ"
      },
      "source": [
        "Training algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGhFs-iMjDJ3"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        train_losses = []\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHQGyujWTp4V"
      },
      "source": [
        "Actual training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZHnjdoQjqdm",
        "outputId": "cfe1e8f8-3e1d-4a09-8795-c9f27e894de3"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 5e-5\n",
        "\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgtLTFVPSOG5"
      },
      "source": [
        "## Step 3: Save Model and Display Statistics üìà"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "62efg1Ppj-Z7",
        "outputId": "09a7620c-0add-4ccc-c77a-9df0c94f7d67"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "JMRTdqYL60kK",
        "outputId": "3d1f5786-c51d-441f-e5c8-d94ddbcc1703"
      },
      "outputs": [],
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After plotting accuracies and losses, save the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs3K2VV9n8WB",
        "outputId": "d36c7bd9-6d52-4dfa-b80b-6cb2a700a7f0"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'AlexNetNew_May9.pt'\n",
        "path = f\"/content/drive/MyDrive/Colab Notebooks/TrashModels/{model_save_name}\"\n",
        "torch.save(model, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hLDLURLgIuP"
      },
      "source": [
        "## Step 4: Analyze and Judge Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkRbF46ZsRu2"
      },
      "outputs": [],
      "source": [
        "model = ResNet50()\n",
        "model = torch.load('/content/drive/MyDrive/Colab Notebooks/TrashModels/ResNetPT_April17_compost.pt')\n",
        "\n",
        "model.eval()\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI6DhP5g2WMu"
      },
      "outputs": [],
      "source": [
        "def predict_image(img, model):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    \n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    \n",
        "    # Pick index with highest probability\n",
        "    prob, preds  = torch.max(yb, dim=1)\n",
        "    \n",
        "    # Retrieve the class label\n",
        "    return dataset.classes[preds[0].item()]\n",
        "\n",
        "img, label = test_ds[17]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))\n",
        "\n",
        "img, label = test_ds[23]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))\n",
        "\n",
        "img, label = test_ds[80]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use `sklearn`, `seaborn`, `pandas` to plot metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q1ICAgua8LP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "y_pred, y_true = [], []\n",
        "\n",
        "# Iterate over test data\n",
        "for img, label in test_ds:\n",
        "        y_pred.append(predict_image(img, model)) # Save Prediction\n",
        "        y_true.append(dataset.classes[label]) # Save Truth\n",
        "\n",
        "print(y_pred)\n",
        "print(y_true)\n",
        "\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('output.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "N63RbH4MR5-y"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
